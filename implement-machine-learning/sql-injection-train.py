# import pandas as pd
# import string
# import re
# import numpy as np
# from sklearn.model_selection import train_test_split
# from sklearn.preprocessing import StandardScaler
# from sklearn.ensemble import RandomForestClassifier
# from sklearn.metrics import accuracy_score
# from sklearn.feature_extraction.text import TfidfVectorizer
# from sklearn.pipeline import make_pipeline
# from sklearn.metrics import classification_report
# from sklearn.linear_model import LogisticRegression
# from sklearn.metrics import accuracy_score, classification_report
# from xgboost import XGBClassifier
# from sklearn.svm import SVC

# # ƒê·ªçc file CSV
# df = pd.read_csv("/content/Modified_SQL_Dataset.csv")

# # H√†m ki·ªÉm tra c√≥ kho·∫£ng tr·∫Øng hay kh√¥ng
# df["have_space"] = df["Query"].str.contains(r"\s", regex=True)

# # H√†m ki·ªÉm tra c√≥ k√Ω t·ª± ƒë·∫∑c bi·ªát hay kh√¥ng (kh√¥ng ph·∫£i ch·ªØ c√°i, s·ªë, ho·∫∑c kho·∫£ng tr·∫Øng)
# special_chars = re.compile(r"[^a-zA-Z0-9\s]")
# df["have_unique_text"] = df["Query"].apply(lambda x: bool(special_chars.search(str(x))))

# # ƒê·∫øm s·ªë kho·∫£ng tr·∫Øng trong c√¢u
# df["count_space"] = df["Query"].str.count(r"\s")

# # ƒê·∫øm s·ªë k√Ω t·ª± ƒë·∫∑c bi·ªát trong c√¢u
# df["count_unique_text"] = df["Query"].apply(lambda x: len(re.findall(r"[^a-zA-Z0-9\s]", str(x))))

# # Hi·ªÉn th·ªã 5 d√≤ng ƒë·∫ßu ƒë·ªÉ ki·ªÉm tra
# # print(df.head())

# print(df["Label"].value_counts())

# ######################################################################

# # Chuy·ªÉn ƒë·ªïi c·ªôt Boolean th√†nh s·ªë (True -> 1, False -> 0)
# df["have_space"] = df["have_space"].astype(int)
# df["have_unique_text"] = df["have_unique_text"].astype(int)

# vectorizer = TfidfVectorizer(max_features=1000)  # Gi·ªõi h·∫°n s·ªë l∆∞·ª£ng ƒë·∫∑c tr∆∞ng
# X_text_features = vectorizer.fit_transform(df["Query"]).toarray()

# y = df["Label"]

# # G·ªôp ƒë·∫∑c tr∆∞ng vƒÉn b·∫£n v·ªõi c√°c ƒë·∫∑c tr∆∞ng s·ªë
# X_numeric = df[["have_space", "have_unique_text", "count_space", "count_unique_text"]].values
# X_combined = np.hstack((X_text_features, X_numeric))

# X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.3, random_state=42)

# # Chu·∫©n h√≥a d·ªØ li·ªáu (t√πy ch·ªçn, c√≥ th·ªÉ b·ªè qua)
# scaler = StandardScaler()
# X_train_scaled = scaler.fit_transform(X_train)
# X_test_scaled = scaler.transform(X_test)

# ######################################################################

# # Kh·ªüi t·∫°o v√† hu·∫•n luy·ªán m√¥ h√¨nh
# model = RandomForestClassifier(n_estimators=100, random_state=42)
# model.fit(X_train_scaled, y_train)


# # D·ª± ƒëo√°n tr√™n t·∫≠p ki·ªÉm tra
# y_pred = model.predict(X_test_scaled)

# # ƒê√°nh gi√° ƒë·ªô ch√≠nh x√°c
# accuracy = accuracy_score(y_test, y_pred)
# # print(f"Accuracy: {accuracy:.2f}")

# print(classification_report(y_test, y_pred))

# train_accuracy = model.score(X_train_scaled, y_train)
# test_accuracy = model.score(X_test_scaled, y_test)

# print(f"Train Accuracy: {train_accuracy:.4f} -- Test Accuracy: {test_accuracy:.4f}")

# ######################################################################

# logreg = LogisticRegression(max_iter=1000, random_state=42)
# logreg.fit(X_train_scaled, y_train)
# y_pred_logreg = logreg.predict(X_test_scaled)

# print("üìå Logistic Regression")
# print("Accuracy Logistic Regression:", accuracy_score(y_test, y_pred_logreg))
# print(classification_report(y_test, y_pred_logreg))

# train_accuracy = logreg.score(X_train_scaled, y_train)
# test_accuracy = logreg.score(X_test_scaled, y_test)

# print(f"Train Accuracy: {train_accuracy:.4f} -- Test Accuracy: {test_accuracy:.4f}")

# ######################################################################

# xgb = XGBClassifier(n_estimators=100, use_label_encoder=False, eval_metric='logloss', random_state=42)
# xgb.fit(X_train_scaled, y_train)
# y_pred_xgb = xgb.predict(X_test_scaled)

# print("üìå XGBoost")
# print("Accuracy XGBoost:", accuracy_score(y_test, y_pred_xgb))
# print(classification_report(y_test, y_pred_xgb))

# train_accuracy = xgb.score(X_train_scaled, y_train)
# test_accuracy = xgb.score(X_test_scaled, y_test)

# print(f"Train Accuracy: {train_accuracy:.4f} -- Test Accuracy: {test_accuracy:.4f}")

# ######################################################################

# svm = SVC(kernel="linear", random_state=42)
# svm.fit(X_train_scaled, y_train)
# y_pred_svm = svm.predict(X_test_scaled)

# print("üìå Support Vector Machine (SVM)")
# print("Accuracy Support Vector Machine (SVM):", accuracy_score(y_test, y_pred_svm))
# print(classification_report(y_test, y_pred_svm))

# train_accuracy = svm.score(X_train_scaled, y_train)
# test_accuracy = svm.score(X_test_scaled, y_test)

# print(f"Train Accuracy: {train_accuracy:.4f} -- Test Accuracy: {test_accuracy:.4f}")